{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #import pandas\n",
    "import numpy as numpy #import numpy\n",
    "from sklearn.utils import shuffle # to shuffle the data \n",
    "import random # import random\n",
    "import sklearn # import sklearn\n",
    "import nltk # import nltk\n",
    "from nltk.corpus import stopwords #import stop words\n",
    "import re # import regular expression\n",
    "from nltk.tokenize import word_tokenize # import word_tokenize\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt #import matplotlib.pyplot\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Terminator/Downloads/file/data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1701</td>\n",
       "      <td>#sxswnui #sxsw #apple defining language of tou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1851</td>\n",
       "      <td>Learning ab Google doodles! All doodles should...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2689</td>\n",
       "      <td>one of the most in-your-face ex. of stealing t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4525</td>\n",
       "      <td>This iPhone #SXSW app would b pretty awesome i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3604</td>\n",
       "      <td>Line outside the Apple store in Austin waiting...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                              tweet  sentiment\n",
       "0      1701  #sxswnui #sxsw #apple defining language of tou...          1\n",
       "1      1851  Learning ab Google doodles! All doodles should...          1\n",
       "2      2689  one of the most in-your-face ex. of stealing t...          2\n",
       "3      4525  This iPhone #SXSW app would b pretty awesome i...          0\n",
       "4      3604  Line outside the Apple store in Austin waiting...          1"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4311\n",
       "2    2382\n",
       "0     456\n",
       "3     125\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e9376a44a8>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.sentiment.value_counts().plot(kind='pie', autopct='%1.0f%%', colors=[\"pink\", \"yellow\", \"green\",\"blue\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pre_clean_len'] = [len(str(t)) for t in df.tweet]\n",
    "# add new column pre_clean_len to dataframe which is length of each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>pre_clean_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1701</td>\n",
       "      <td>#sxswnui #sxsw #apple defining language of tou...</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1851</td>\n",
       "      <td>Learning ab Google doodles! All doodles should...</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2689</td>\n",
       "      <td>one of the most in-your-face ex. of stealing t...</td>\n",
       "      <td>2</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4525</td>\n",
       "      <td>This iPhone #SXSW app would b pretty awesome i...</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3604</td>\n",
       "      <td>Line outside the Apple store in Austin waiting...</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                              tweet  sentiment  \\\n",
       "0      1701  #sxswnui #sxsw #apple defining language of tou...          1   \n",
       "1      1851  Learning ab Google doodles! All doodles should...          1   \n",
       "2      2689  one of the most in-your-face ex. of stealing t...          2   \n",
       "3      4525  This iPhone #SXSW app would b pretty awesome i...          0   \n",
       "4      3604  Line outside the Apple store in Austin waiting...          1   \n",
       "\n",
       "   pre_clean_len  \n",
       "0             89  \n",
       "1            143  \n",
       "2            132  \n",
       "3            125  \n",
       "4             77  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(df.pre_clean_len) # plot pre_clean_len column\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>pre_clean_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1851</td>\n",
       "      <td>Learning ab Google doodles! All doodles should...</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1779</td>\n",
       "      <td>@mention 2 heck w/being sick, #Apple is suppos...</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>6615</td>\n",
       "      <td>RT @mention RT @mention Tweet this to register...</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>6669</td>\n",
       "      <td>RT @mention So it appears Apple is opening a p...</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>5174</td>\n",
       "      <td>RT @mention &amp;quot;Everyone here already has on...</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>7974</td>\n",
       "      <td>I still use Tweetie for Mac &amp;amp; I'm running ...</td>\n",
       "      <td>2</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>6652</td>\n",
       "      <td>RT @mention Server Challenge is a huge hit at ...</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>6427</td>\n",
       "      <td>RT @mention Over 100 in line at Apple pop-up s...</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>5169</td>\n",
       "      <td>RT @mention &amp;quot;Apple likes it if you pay th...</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>4509</td>\n",
       "      <td>#sxsw: #indieauthors: Sanders: &amp;quot;One autho...</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id                                              tweet  sentiment  \\\n",
       "1        1851  Learning ab Google doodles! All doodles should...          1   \n",
       "74       1779  @mention 2 heck w/being sick, #Apple is suppos...          1   \n",
       "96       6615  RT @mention RT @mention Tweet this to register...          1   \n",
       "98       6669  RT @mention So it appears Apple is opening a p...          1   \n",
       "114      5174  RT @mention &quot;Everyone here already has on...          1   \n",
       "154      7974  I still use Tweetie for Mac &amp; I'm running ...          2   \n",
       "169      6652  RT @mention Server Challenge is a huge hit at ...          1   \n",
       "200      6427  RT @mention Over 100 in line at Apple pop-up s...          1   \n",
       "232      5169  RT @mention &quot;Apple likes it if you pay th...          1   \n",
       "236      4509  #sxsw: #indieauthors: Sanders: &quot;One autho...          1   \n",
       "\n",
       "     pre_clean_len  \n",
       "1              143  \n",
       "74             141  \n",
       "96             143  \n",
       "98             152  \n",
       "114            155  \n",
       "154            142  \n",
       "169            142  \n",
       "200            150  \n",
       "232            143  \n",
       "236            144  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.pre_clean_len > 140].head(10)  \n",
    "# check for any tweets greater than 140 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tok = WordPunctTokenizer()\n",
    "\n",
    "# remove @ mentions fron tweets\n",
    "pat1 = r'@[A-Za-z0-9_]+'        \n",
    "\n",
    "# remove URL's from tweets\n",
    "pat2 = r'https?://[^ ]+'        \n",
    "\n",
    "#addition of pat1 and pat2\n",
    "combined_pat = r'|'.join((pat1, pat2)) \n",
    "\n",
    "# remove URL's from tweets\n",
    "www_pat = r'www.[^ ]+'         \n",
    "\n",
    "# converting words like isn't to is not\n",
    "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",   \n",
    "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                \"mustn't\":\"must not\"}\n",
    "\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
    "\n",
    "# define tweet_cleaner function to clean the tweets\n",
    "def tweet_cleaner(text):\n",
    "    # call beautiful object\n",
    "    soup = BeautifulSoup(text, 'lxml')    \n",
    "    souped = soup.get_text()   # get only text from the tweets \n",
    "    try:\n",
    "        bom_removed = souped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")    # remove utf-8-sig codeing\n",
    "    except:\n",
    "        bom_removed = souped\n",
    "    stripped = re.sub(combined_pat, '', bom_removed) # calling combined_pat\n",
    "    stripped = re.sub(www_pat, '', stripped) #remove URL's\n",
    "    lower_case = stripped.lower()      # converting all into lower case\n",
    "    \n",
    "    # converting word's like isn't to is not\n",
    "    neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], lower_case) \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", neg_handled)       # will replace # by space\n",
    "    \n",
    "    # Word Punct Tokenize and only consider words whose length is greater than 1\n",
    "    words = [x for x  in tok.tokenize(letters_only) if len(x) > 1] \n",
    "    return (\" \".join(words)).strip() # join the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweet_texts = [] # initialize list\n",
    "\n",
    "for i in range(0,7274):\n",
    "    clean_tweet_texts.append(tweet_cleaner(str(df['tweet'][i])))\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Terminator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokens = [] # initialize list for tokens\n",
    "for word in clean_tweet_texts:  # for each word in clean_tweet_texts\n",
    "    word_tokens.append(word_tokenize(word)) \n",
    "    #tokenize word in clean_tweet_texts and append it to word_tokens list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Terminator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = [] # initialize list df1 to store words after lemmatization\n",
    "from nltk.stem import WordNetLemmatizer # import WordNetLemmatizer from nltk.stem\n",
    "lemmatizer = WordNetLemmatizer() # create an object of WordNetLemmatizer\n",
    "for l in word_tokens: # for loop for every tokens in word_token\n",
    "    b = [lemmatizer.lemmatize(q) for q in l] #for every tokens in word_token lemmatize word and giev it to b\n",
    "    df1.append(b) #append b to list df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df1 =[] # initialize list clean_df1 to join word tokens after lemmatization\n",
    "for c in df1:  # for loop for each list in df1\n",
    "    a = \" \".join(c) # join words in list with space in between and giev it to a\n",
    "    clean_df1.append(a) # append a to clean_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.DataFrame(clean_df1,columns=['text']) # convert clean_tweet_texts into dataframe and name it as clean_df\n",
    "clean_df['target'] = df.sentiment # from earlier dataframe get the sentiments of each tweet and make a new column in clean_df as target and give it all the sentiment score\n",
    "#clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['clean_len'] = [len(t) for t in clean_df.text] # Again make a new coloumn in the dataframe and name it as clean_len which will store thw number of words in the tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, target, clean_len]\n",
       "Index: []"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df[clean_df.clean_len > 140].head(10) # agin check id any tweet is more than 140 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7274,)\n",
      "(7274,)\n"
     ]
    }
   ],
   "source": [
    "X = clean_df.text # get all the text in x variable\n",
    "y = clean_df.target # get all the sentiments into y variable\n",
    "print(X.shape) #print shape of x\n",
    "print(y.shape) # print shape of y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sxswnui sxsw apple defining language of touch ...</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>learning ab google doodle all doodle should be...</td>\n",
       "      <td>1</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one of the most in your face ex of stealing th...</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this iphone sxsw app would pretty awesome if i...</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>line outside the apple store in austin waiting...</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  clean_len\n",
       "0  sxswnui sxsw apple defining language of touch ...       1         85\n",
       "1  learning ab google doodle all doodle should be...       1        127\n",
       "2  one of the most in your face ex of stealing th...       2        102\n",
       "3  this iphone sxsw app would pretty awesome if i...       0        117\n",
       "4  line outside the apple store in austin waiting...       1         73"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split #from sklearn.cross_validation import train_test_split to split the data into training and tesing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state= 0) # split the data into traing and testing set where ratio is 80:20\n",
    "\n",
    "\n",
    "# X_train is the tweets of training data, X_test is the testing tweets which we have to predict, y_train is the sentiments of tweets in the traing data and y_test is the sentiments of the tweets  which we will use to measure the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(analyzer = \"word\", ngram_range=(1,3)) # Get Tf-idf object and save it as vect. We can select features from here we just have simply change \n",
    "                                                                                     #the ngram range to change the features also we can remove stop words over here with the help of stop parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.fit(X_train) # fit or traing data tweets to vect\n",
    "X_train_dtm = vect.transform(X_train) # transform our training data tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_dtm = vect.transform(X_test)# transform our testing data tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB # import Multinomial Naive Bayes model from sklearn.naive_bayes\n",
    "nb = MultinomialNB(alpha = 10) # get object of Multinomial naive bayes model with alpha parameter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=10, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_train_dtm, y_train)# fit our both traing data tweets as well as its sentiments to the multinomial naive bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5999319820555179"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score  # import cross_val_score from sklear.model_selection\n",
    "accuracies_nb = cross_val_score(estimator = nb, X = X_train_dtm, y = y_train, cv = 10) # do K- fold cross validation on our traing data and its sentimenst with 10 fold cross validation\n",
    "accuracies_nb.mean() # measure the mean accuray of 10 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nb = nb.predict(X_test_dtm) # predict the sentiments of testing data tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6027491408934708"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics # import metrics from sklearn\n",
    "metrics.accuracy_score(y_test, y_pred_nb) # measure the accuracy of our model on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  92,   0,   0],\n",
       "       [  0, 871,   0,   0],\n",
       "       [  0, 467,   6,   0],\n",
       "       [  0,  19,   0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix # import confusion matrix from the sklearn.metrics\n",
    "confusion_matrix(y_test, y_pred_nb) # plot the confusion matrix between our predicted sentiments and the original testing data sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6027491408934708"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score_nb = f1_score(y_test, y_pred_nb,average='micro')\n",
    "f1_score_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression # import Logistic Regression model from sklearn.linear_model\n",
    "logisticRegr = LogisticRegression(C = 1.1) # get object of logistic regression model with cost parameter = 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.fit(X_train_dtm, y_train)# fit our both traing data tweets as well as its sentiments to the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6456445581079582"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score # import cross_val_score from sklear.model_selection\n",
    "accuracies = cross_val_score(estimator = logisticRegr, X = X_train_dtm, y = y_train, cv = 10) # do K- fold cross validation on our traing data and its sentimenst with 10 fold cross validation\n",
    "accuracy_log=accuracies.mean() # measure the mean accuray of 10 fold cross validation\n",
    "accuracy_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lg = logisticRegr.predict(X_test_dtm)  # predict the sentiments of testing data tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6577319587628866"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics # import metrics from sklearn\n",
    "metrics.accuracy_score(y_test, y_pred_lg) # measure the accuracy of our model on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6577319587628866"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score_lg = f1_score(y_test, y_pred_lg,average='micro')\n",
    "f1_score_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3,  71,  18,   0],\n",
       "       [  1, 786,  84,   0],\n",
       "       [  0, 305, 168,   0],\n",
       "       [  1,  12,   6,   0]], dtype=int64)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix # import confusion matrix from the sklearn.metrics\n",
    "confusion_matrix(y_test, y_pred_lg) # plot the confusion matrix between our predicted sentiments and the original testing data sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC # import SVC model from sklearn.svm\n",
    "svm_clf = LinearSVC(random_state=0) # get object of SVC model with random_state parameter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.fit(X_train_dtm, y_train)# fit our both traing data tweets as well as its sentiments to the SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6769291455762128"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score  # import cross_val_score from sklear.model_selection\n",
    "accuracies = cross_val_score(estimator = svm_clf, X = X_train_dtm, y = y_train, cv = 10)# do K- fold cross validation on our traing data and its sentimenst with 10 fold cross validation\n",
    "accuracies.mean() # measure the mean accuray of 10 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = svm_clf.predict(X_test_dtm)  # predict the sentiments of testing data tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6769759450171822"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics  # import metrics from sklearn\n",
    "metrics.accuracy_score(y_test, y_pred_svm)  # measure the accuracy of our model on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6769759450171822"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score_svm = f1_score(y_test, y_pred_svm,average='micro')\n",
    "f1_score_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train_dtm, y_train)# fit our both traing data tweets as well as its sentiments to the random forest model model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6408320869442503"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score  # import cross_val_score from sklear.model_selection\n",
    "accuracies = cross_val_score(estimator = rfc, X = X_train_dtm, y = y_train, cv = 10)# do K- fold cross validation on our traing data and its sentimenst with 10 fold cross validation\n",
    "accuracies.mean() # measure the mean accuray of 10 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfc = rfc.predict(X_test_dtm)  # predict the sentiments of testing data tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6274914089347079"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics  # import metrics from sklearn\n",
    "metrics.accuracy_score(y_test, y_pred_rfc)  # measure the accuracy of our model on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 13,  63,  16,   0],\n",
       "       [  6, 773,  90,   2],\n",
       "       [  0, 344, 127,   2],\n",
       "       [  1,  16,   2,   0]], dtype=int64)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix # import confusion matrix from the sklearn.metrics\n",
    "confusion_matrix(y_test, y_pred_rfc)# plot the confusion matrix between our predicted sentiments and the original testing data sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6274914089347079"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score_rfc = f1_score(y_test, y_pred_rfc,average='micro')\n",
    "f1_score_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\terminator\\anaconda3\\lib\\site-packages (0.90)\n",
      "Requirement already satisfied: numpy in c:\\users\\terminator\\anaconda3\\lib\\site-packages (from xgboost) (1.15.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\terminator\\anaconda3\\lib\\site-packages (from xgboost) (1.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "twisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed.\n",
      "You are using pip version 10.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf=DecisionTreeClassifier(max_depth=2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(base_estimator=dt_clf, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Score:  0.6426116838487973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Terminator\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "xgb_clf.fit(X_train_dtm,y_train)\n",
    "xgb_score = xgb_clf.score(X_test_dtm,y_test)\n",
    "print(\"XGBoost Score: \",xgb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Terminator\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_pred_xgb = xgb_clf.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6426116838487973"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics  # import metrics from sklearn\n",
    "metrics.accuracy_score(y_test, y_pred_xgb)  # measure the accuracy of our model on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6,  79,   7,   0],\n",
       "       [  1, 835,  35,   0],\n",
       "       [  0, 379,  94,   0],\n",
       "       [  0,  15,   4,   0]], dtype=int64)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix # import confusion matrix from the sklearn.metrics\n",
    "confusion_matrix(y_test, y_pred_xgb)# plot the confusion matrix between our predicted sentiments and the origina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6426116838487973"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score_xgb = f1_score(y_test, y_pred_xgb,average='micro')\n",
    "f1_score_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost 1 Score:  0.6563573883161512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Terminator\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "xgb1.fit(X_train_dtm,y_train)\n",
    "xgb1_score = xgb1.score(X_test_dtm,y_test)\n",
    "print(\"XGBoost 1 Score: \",xgb1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada boost Score:  0.5958762886597938\n"
     ]
    }
   ],
   "source": [
    "ada_clf = AdaBoostClassifier(base_estimator=dt_clf,random_state=0)\n",
    "ada_clf.fit(X_train_dtm,y_train)\n",
    "ada_score = ada_clf.score(X_test_dtm,y_test)\n",
    "print(\"Ada boost Score: \",ada_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting_clf score:  0.6556701030927835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Terminator\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Terminator\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Terminator\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Terminator\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 12,  69,  11,   0],\n",
       "       [  5, 827,  38,   1],\n",
       "       [  0, 358, 115,   0],\n",
       "       [  1,  15,   3,   0]], dtype=int64)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = LogisticRegression(random_state=0)\n",
    "model2 = DecisionTreeClassifier(random_state=0)\n",
    "model3 = RandomForestClassifier(random_state=0)\n",
    "model4 = LinearSVC()\n",
    "model5 = XGBClassifier()\n",
    "model6 = AdaBoostClassifier()\n",
    "Voting_clf = VotingClassifier(estimators=[('lr', model1), ('dt', model2), ('rf',model3), ('sv',model4),('xg',model5),('ad',model6)], voting='hard')\n",
    "Voting_clf.fit(X_train_dtm,y_train)\n",
    "score_voting=Voting_clf.score(X_test_dtm,y_test)\n",
    "print(\"Voting_clf score: \",score_voting)\n",
    "y_pred_vote = Voting_clf.predict(X_test_dtm)\n",
    "confusion_matrix(y_test, y_pred_vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TESTING DATA ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv=pd.read_csv(\"C:/Users/Terminator/Downloads/file/data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7506</td>\n",
       "      <td>Audience Q: What prototyping tools do you use?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7992</td>\n",
       "      <td>At SXSW? Send Your Best Photos &amp;amp; Videos to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>247</td>\n",
       "      <td>@mention  and here's a pic of you winning your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7688</td>\n",
       "      <td>Google Marissa Mayer: mobile phone as a cursor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3294</td>\n",
       "      <td>#SXSW Google maps is even cooler than I thought</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                              tweet\n",
       "0      7506  Audience Q: What prototyping tools do you use?...\n",
       "1      7992  At SXSW? Send Your Best Photos &amp; Videos to...\n",
       "2       247  @mention  and here's a pic of you winning your...\n",
       "3      7688  Google Marissa Mayer: mobile phone as a cursor...\n",
       "4      3294    #SXSW Google maps is even cooler than I thought"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet=test_csv['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweet_test = [] # initialize list\n",
    "\n",
    "for i in range(0,1819):\n",
    "    clean_tweet_test.append(tweet_cleaner(str(test_csv['tweet'][i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokens_test = [] # initialize list for tokens\n",
    "for word in clean_tweet_test:  # for each word in clean_tweet_texts\n",
    "    word_tokens_test.append(word_tokenize(word)) \n",
    "    #tokenize word in clean_tweet_texts and append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = [] # initialize list df1 to store words after lemmatization\n",
    "from nltk.stem import WordNetLemmatizer # import WordNetLemmatizer from nltk.stem\n",
    "lemmatizer = WordNetLemmatizer() # create an object of WordNetLemmatizer\n",
    "for l in word_tokens_test: # for loop for every tokens in word_token\n",
    "    b = [lemmatizer.lemmatize(q) for q in l] #for every tokens in word_token lemmatize word and giev it to b\n",
    "    df2.append(b) #append b to list df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df2 =[] # initialize list clean_df1 to join word tokens after lemmatization\n",
    "for c in df2:  # for loop for each list in df1\n",
    "    a = \" \".join(c) # join words in list with space in between and giev it to a\n",
    "    clean_df2.append(a) # append a to clean_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_test = pd.DataFrame(clean_df2,columns=['tweet']) # convert clean_tweet_texts into dataframe and name it as clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_test['clean_len'] = [len(t) for t in clean_df_test.tweet] # Again make a new coloumn in the dataframe and name it as clean_len which will store thw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [tweet, clean_len]\n",
       "Index: []"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df_test[clean_df_test.clean_len > 140].head(10) # agin check id any tweet is more than 140 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_tweet = clean_df_test.tweet # get all the text in x variabl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audience what prototyping tool do you use sket...</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>at sxsw send your best photo video to link cit...</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and here pic of you winning your ipad unsix sx...</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google marissa mayer mobile phone a cursor of ...</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sxsw google map is even cooler than thought</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  clean_len\n",
       "0  audience what prototyping tool do you use sket...        122\n",
       "1  at sxsw send your best photo video to link cit...        103\n",
       "2  and here pic of you winning your ipad unsix sx...         66\n",
       "3  google marissa mayer mobile phone a cursor of ...        116\n",
       "4        sxsw google map is even cooler than thought         43"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect1 = TfidfVectorizer(analyzer = \"word\", ngram_range=(1,3)) # Get Tf-idf object and save it as vect. We can select features from here we just have simply change \n",
    "                                                                                     #the ngram range to change the features also we can remove stop words over here with the help of stop parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect1.fit(Test_tweet) # fit or traing data tweets to vect\n",
    "X_train_test = vect.transform(Test_tweet) # transform our training data tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Terminator\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Terminator\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "clean_df_test['sentiment']=Voting_clf.predict(X_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_len</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audience what prototyping tool do you use sket...</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>at sxsw send your best photo video to link cit...</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and here pic of you winning your ipad unsix sx...</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google marissa mayer mobile phone a cursor of ...</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sxsw google map is even cooler than thought</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  clean_len  sentiment\n",
       "0  audience what prototyping tool do you use sket...        122          1\n",
       "1  at sxsw send your best photo video to link cit...        103          1\n",
       "2  and here pic of you winning your ipad unsix sx...         66          1\n",
       "3  google marissa mayer mobile phone a cursor of ...        116          1\n",
       "4        sxsw google map is even cooler than thought         43          2"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submit = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submit['tweet_id']=test_csv['tweet_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submit['sentiment']=clean_df_test['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  tweet_id\n",
       "0          1      7506\n",
       "1          1      7992\n",
       "2          1       247\n",
       "3          1      7688\n",
       "4          2      3294"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1819, 2)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submit.to_csv('C:/Users/Terminator/Downloads/file/data/Submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
